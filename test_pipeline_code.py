"""
====================================================================================
Fichier : test_pipeline_code.py
Objectif : Automatisation de la mise √† jour des m√©triques + g√©n√©ration de backtests via BoTorch
====================================================================================

Description :
Ce script assure deux fonctions critiques dans un pipeline d‚Äôexploration de strat√©gies
quantitatives :

1. **Nettoyage et enrichissement de la base de donn√©es (`good_iterations.db`)**
   - V√©rification de la pr√©sence des colonnes n√©cessaires dans la table `trades`
     (sharpe_ratio, max_drawdown, profit_factor, win_rate)
   - Calcul de ces m√©triques pour chaque `backtest_id`, sur la base des PnL nets agr√©g√©s
   - Propagation coh√©rente des scores √† toutes les lignes du `backtest_id` concern√©

2. **Lancement de nouveaux backtests via des suggestions d‚Äôhyperparam√®tres BoTorch**
   - Utilise un mod√®le bay√©sien pour g√©n√©rer intelligemment des combinaisons prometteuses
   - Ex√©cute `run_backtest_from_params()` sur chaque combinaison
   - Alimente dynamiquement la base `trades` avec de nouvelles observations

R√¥le dans le pipeline :
Ce script peut √™tre vu comme une brique *AutoML supervis√©e* dans un cadre de
recherche de strat√©gie algorithmique :
    - Il enrichit les donn√©es historiques avec des m√©triques robustes
    - Il stimule activement de nouvelles explorations via BoTorch (Bayesian Optimization)
    - Il maintient une base SQL exploitable par le RL ou la s√©lection statistique

Sp√©cificit√©s :
    - M√©triques calcul√©es au niveau agr√©g√© (par backtest), √©vitant les biais ligne par ligne
    - M√©thodologie robuste de calcul : Sharpe, drawdown, profit factor, win rate
    - Les suggestions BoTorch permettent une am√©lioration dirig√©e, non al√©atoire, du front Pareto

√Ä combiner avec :
    - `good_iterations.db` (base centrale du pipeline)
    - `gp_driver.py` (mod√©lisation BoTorch)
    - `run_backtest_from_params()` (ex√©cution d‚Äôun backtest isol√©)
    - `generate_pca_test_features.py` (pr√©paration post-backtest pour RL)
    - `ppo_train.py` (agent RL utilisant les strat√©gies les plus robustes)

Utilisation recommand√©e :
Ce script peut √™tre lanc√© √† intervalles r√©guliers pour :
    - nettoyer et stabiliser la base SQL
    - d√©clencher des backtests intelligents (Bayesian Exploration)
    - servir de boucle ferm√©e dans un processus *AutoML RL-based Backtesting*

Auteur : Moncoucut Brandon
Version : Juin 2025
"""

# === Imports fondamentaux ===
import sqlite3
import pandas as pd
import numpy as np
from typing import Dict, Any, Tuple
from gp_driver import suggest_from_gp
from backtest_interface_code import run_backtest_from_params

# ‚úÖ KPI standardis√©s
import metrics_core as mx

# ‚úÖ Helpers DB (init/migration + upsert KPI)
from backtest_db_manager import (
    init_sqlite_database,
    migrate_sqlite_schema,
    upsert_kpis,
)

# === CONFIGURATION ===
USE_BOTORCH = True
N_BOTORCH_TRIALS = 3
DB_PATH = "/Users/brandonmoncoucut/Desktop/Najas_king/log_sqlite/good_iterations.db"
TRADES_TABLE = "trades"

def _sanitize_kpi(kpi: Dict[str, Any]) -> Dict[str, Any]:
    """
    Remplace NaN/Inf par None pour compatibilit√© SQLite/JSON.
    Conserve uniquement des scalaires num√©riques (int/float) ou None.

    Args:
        kpi: Dictionnaire de KPI calcul√©s.

    Returns:
        Dict[str, Any]: KPI nettoy√©s.
    """
    clean: Dict[str, Any] = {}
    if not isinstance(kpi, dict):
        return clean
    for k, v in kpi.items():
        try:
            if v is None:
                clean[k] = None
            elif isinstance(v, (int,)) and not isinstance(v, bool):
                clean[k] = int(v)
            elif isinstance(v, float):
                clean[k] = None if (np.isnan(v) or np.isinf(v)) else float(v)
            else:
                clean[k] = None
        except Exception:
            clean[k] = None
    return clean

# === AJOUT DES COLONNES MANQUANTES ===
def ensure_columns_exist():
    """
    Initialise la base r√©sultats et applique une migration idempotente :
      - cr√©e les tables manquantes (logs, trades, kpi_by_backtest),
      - ajoute les nouvelles colonnes si n√©cessaire (equity/pnl_step/drawdown/fees...).

    Remplace l'ancien ajout manuel de colonnes dans `trades`.
    """
    init_sqlite_database(DB_PATH)
    migrate_sqlite_schema(DB_PATH)

# === CALCULS DES COLONNES MANQUANTES ===
def update_performance_metrics():
    """
    Recalcule les KPI standardis√©s pour chaque `backtest_id` √† partir des tables
    `trades` (obligatoire) et `logs` (optionnelle), puis fait un UPSERT dans
    `kpi_by_backtest` via `upsert_kpis`.

    D√©tails:
    - Fallback timestamp: utilise 'timestamp' si pr√©sent, sinon 'exit_time'.
    - Iteration: prend la valeur la plus fr√©quente (mode) pour le backtest_id, sinon max().
    - Sanitisation: NaN/Inf ‚Üí None avant UPSERT (compat SQLite).
    """
    print("üìä Recalcul des KPI standardis√©s (kpi_by_backtest)...")
    with sqlite3.connect(DB_PATH) as conn:
        trades = pd.read_sql_query("SELECT * FROM trades", conn)
        try:
            logs = pd.read_sql_query("SELECT * FROM logs", conn)
        except Exception:
            logs = pd.DataFrame()

    if trades.empty:
        print("‚ö†Ô∏è Table 'trades' vide ‚Äî rien √† recalculer.")
        return

    # Partition par backtest_id
    for bid, grp in trades.groupby("backtest_id"):
        df_tr = grp.copy()

        # Choix du timestamp de r√©f√©rence
        ts_col = "timestamp" if "timestamp" in df_tr.columns else ("exit_time" if "exit_time" in df_tr.columns else None)
        if ts_col is not None:
            df_tr[ts_col] = pd.to_datetime(df_tr[ts_col], errors="coerce", utc=True)
            df_tr = df_tr.sort_values(ts_col)

        # Sous-ensemble des logs correspondant (si disponible)
        if not logs.empty and "backtest_id" in logs.columns:
            df_lg = logs[logs["backtest_id"] == bid].copy()
            if not df_lg.empty:
                lg_ts = "timestamp" if "timestamp" in df_lg.columns else None
                if lg_ts is not None:
                    df_lg[lg_ts] = pd.to_datetime(df_lg[lg_ts], errors="coerce", utc=True)
                    df_lg = df_lg.sort_values(lg_ts)
            else:
                df_lg = None
        else:
            df_lg = None

        # Calcul KPI (tol√®re colonnes manquantes ‚Üí NaN cibl√©s)
        try:
            kpi_raw = mx.compute_intraday_consistency_kpis(
                df_trades=df_tr,
                df_logs=df_lg,
                price_col="price",
                timestamp_col=ts_col or "timestamp",
                fee_rate=0.0
            )
            kpi = _sanitize_kpi(kpi_raw)
        except Exception as e:
            print(f"[WARN] KPI √©chou√©s pour {bid}: {e}")
            continue

        # Iteration robuste (mode; fallback = max; d√©faut = 0)
        iter_val = 0
        if "iteration" in df_tr.columns:
            try:
                iter_mode = df_tr["iteration"].mode(dropna=True)
                iter_val = int(iter_mode.iloc[0]) if not iter_mode.empty else int(df_tr["iteration"].max())
            except Exception:
                try:
                    iter_val = int(df_tr["iteration"].iloc[0])
                except Exception:
                    iter_val = 0

        # UPSERT en base
        try:
            upsert_kpis(DB_PATH, backtest_id=str(bid), iteration=iter_val, kpi=kpi)
        except Exception as e:
            print(f"[WARN] UPSERT KPI √©chou√© pour {bid}: {e}")

    print("‚úÖ Recalcul KPI termin√©.")

def compute_and_propagate_metrics():
    """
    Wrapper conserv√© pour compatibilit√© : d√©clenche simplement le recalcul KPI
    standardis√© (kpi_by_backtest). Plus aucune propagation colonne-√†-colonne dans
    `trades` (obsol√®te).
    """
    update_performance_metrics()

# === TEST AUTOML AVEC GP (BoTorch) ===
def run_tests_with_gp():
    """
    Lance quelques backtests propos√©s par BoTorch et affiche le backtest_id + KPI cl√©s.
    Compatible avec la signature (success, backtest_id, kpi).
    """
    print(f"üì° Test: g√©n√©ration de {N_BOTORCH_TRIALS} points via BoTorch...")
    suggested_params_list = suggest_from_gp(n_trials=N_BOTORCH_TRIALS)

    for i, param_dict in enumerate(suggested_params_list):
        print(f"\nüöÄ Test BoTorch Backtest #{i + 1}")
        success, backtest_id, kpi = run_backtest_from_params(param_dict)
        if success:
            print(f"‚úÖ Test #{i + 1} r√©ussi | backtest_id={backtest_id} | sharpe_d_252={kpi.get('sharpe_d_252')}")
        else:
            print(f"‚ùå Test #{i + 1} √©chou√© | backtest_id={backtest_id}")

# === MAIN EXECUTION ===
if __name__ == "__main__":
    print("üîß Init + migration du sch√©ma SQLite...")
    ensure_columns_exist()  # init + migrate (tables + colonnes)

    print("üßÆ Recalcul des KPI standardis√©s (kpi_by_backtest)...")
    compute_and_propagate_metrics()

    if USE_BOTORCH:
        run_tests_with_gp()